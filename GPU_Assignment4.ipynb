{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1ux6N8PUjC3",
        "outputId": "7354eddd-7b3d-4eab-f0d0-5705404250a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'cuda' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "--2025-06-12 20:34:23--  https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.43.51.10, 23.43.51.15\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.43.51.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4336730777 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘cuda_11.8.0_520.61.05_linux.run’\n",
            "\n",
            "cuda_11.8.0_520.61. 100%[===================>]   4.04G   104MB/s    in 57s     \n",
            "\n",
            "2025-06-12 20:35:20 (72.0 MB/s) - ‘cuda_11.8.0_520.61.05_linux.run’ saved [4336730777/4336730777]\n",
            "\n",
            "Signal caught, cleaning up\n",
            "Signal caught, cleaning up\n",
            "/bin/bash: line 1: nvcc: command not found\n",
            "Thu Jun 12 20:38:38 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!apt-get purge --auto-remove -y cuda\n",
        "!rm -rf /usr/local/cuda*\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
        "!chmod +x cuda_11.8.0_520.61.05_linux.run\n",
        "!./cuda_11.8.0_520.61.05_linux.run --silent --toolkit\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] = '/usr/local/cuda-11.8/bin:' + os.environ['PATH']\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.8/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./cuda_11.8.0_520.61.05_linux.run --silent --toolkit"
      ],
      "metadata": {
        "id": "iT9b9I023fDF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_MrAs124nIT",
        "outputId": "5b2bf078-24bf-4492-e648-cb82747bb208"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Thu Jun 12 20:43:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JN_Pf5PXMtm",
        "outputId": "877c942a-c953-4998-b705-dc1ba165c6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdNLJSsyXP9w",
        "outputId": "f3bde3a0-0fc9-456c-f5e5-37edf9c13363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Using cached pycuda-2025.1.1.tar.gz (1.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Using cached pytools-2025.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Using cached siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.14.0)\n",
            "Using cached pytools-2025.1.6-py3-none-any.whl (95 kB)\n",
            "Using cached siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "Building wheels for collected packages: pycuda\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycuda \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pycuda\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pycuda\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pycuda)\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: nvcc: command not found\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pycuda\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6NbAbh2ZQsF"
      },
      "source": [
        "# **Scalar Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui50wj54X5Yw",
        "outputId": "67b0dfe6-b70b-4097-8c4e-b86c5eb8227d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "904\n",
            "696\n",
            "Name: Muhammad Taha\n",
            "Name ASCII Sum: 904\n",
            "Roll Number: FA22-BCS-119\n",
            "Roll number ASCII Sum: 696\n",
            "904 XOR 696 = 304\n"
          ]
        }
      ],
      "source": [
        "first_name = \"Muhammad Taha\"\n",
        "roll_number = \"FA22-BCS-119\"\n",
        "\n",
        "name_sum = sum(ord(char) for char in first_name.upper())\n",
        "roll_number = str(roll_number)\n",
        "roll_number_sum = sum(ord(char) for char in roll_number)\n",
        "print(name_sum)\n",
        "print(roll_number_sum)\n",
        "S = name_sum ^ roll_number_sum\n",
        "print(f\"Name: {first_name}\")\n",
        "print(f\"Name ASCII Sum: {name_sum}\")\n",
        "print(f\"Roll Number: {roll_number}\")\n",
        "print(f\"Roll number ASCII Sum: {roll_number_sum}\")\n",
        "print(f\"{name_sum} XOR {roll_number_sum} = {S}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-e2lkW8Zdns"
      },
      "source": [
        "# **Cuda Implementation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf9C2vdtZI94",
        "outputId": "cf31dadc-a299-4081-812a-aa13eb6afa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_reduction_simple.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix_reduction_simple.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define MATRIX_SIZE 512\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "#define PERSONALIZED_S 304\n",
        "\n",
        "// Macro to check CUDA errors\n",
        "#define CUDA_CHECK(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "__global__ void conditionalRowReduction(int* matrix, int* result, int S, int matrixSize){\n",
        "  extern __shared__ int sdata[];\n",
        "\n",
        "  int tid = threadIdx.x;\n",
        "  int row = blockIdx.x;\n",
        "\n",
        "  sdata[tid] = 0;\n",
        "\n",
        "  int localSum = 0;\n",
        "  for(int col=tid; col < matrixSize; col+=blockDim.x){\n",
        "    if((row * col)%S<10){\n",
        "      localSum += matrix[row * matrixSize + col];\n",
        "      }\n",
        "    }\n",
        "    sdata[tid] = localSum;\n",
        "    // Perform standard shared memory reduction\n",
        "    // This avoids bank conflicts by using power-of-2 strides\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Thread 0 writes the final result\n",
        "    if (tid == 0) {\n",
        "        result[row] = sdata[0];\n",
        "    }\n",
        "  }\n",
        "  void initializeMatrix(int* matrix, int S, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        for (int j = 0; j < size; j++) {\n",
        "            matrix[i * size + j] = ((i + j) * S) % 100;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "long long calculateTotalSum(int* result, int size) {\n",
        "    long long total = 0;\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        total += result[i];\n",
        "    }\n",
        "    return total;\n",
        "}\n",
        "int main() {\n",
        "    // Use hardcoded personalized scalar\n",
        "    int S = PERSONALIZED_S;\n",
        "\n",
        "    printf(\"=== CUDA Conditional Row-wise Matrix Reduction ===\\\\n\");\n",
        "    printf(\"Matrix Size: %dx%d\\\\n\", MATRIX_SIZE, MATRIX_SIZE);\n",
        "    printf(\"Block Size: %d threads\\\\n\", BLOCK_SIZE);\n",
        "    printf(\"Using personalized scalar S\\n\\n\");\n",
        "\n",
        "    // Host memory allocation\n",
        "    size_t matrixBytes = MATRIX_SIZE * MATRIX_SIZE * sizeof(int);\n",
        "    size_t resultBytes = MATRIX_SIZE * sizeof(int);\n",
        "\n",
        "    int* h_matrix = (int*)malloc(matrixBytes);\n",
        "    int* h_result = (int*)malloc(resultBytes);\n",
        "\n",
        "    if (!h_matrix || !h_result) {\n",
        "        printf(\"Host memory allocation failed!\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Initialize matrix on host\n",
        "    printf(\"Initializing matrix...\\n\");\n",
        "    initializeMatrix(h_matrix, S, MATRIX_SIZE);\n",
        "\n",
        "    // Device memory allocation\n",
        "    int* d_matrix;\n",
        "    int* d_result;\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&d_matrix, matrixBytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_result, resultBytes));\n",
        "\n",
        "    // Transfer matrix to GPU\n",
        "    printf(\"Transferring data to GPU...\\n\");\n",
        "    CUDA_CHECK(cudaMemcpy(d_matrix, h_matrix, matrixBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Configure kernel launch parameters\n",
        "    dim3 gridSize(MATRIX_SIZE, 1, 1);    // 512 blocks (one per row)\n",
        "    dim3 blockSize(BLOCK_SIZE, 1, 1);    // 256 threads per block\n",
        "    size_t sharedMemSize = BLOCK_SIZE * sizeof(int);\n",
        "\n",
        "    // Create CUDA events for precise timing\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "    // Warm up the GPU to get accurate timing\n",
        "    conditionalRowReduction<<<gridSize, blockSize, sharedMemSize>>>(d_matrix, d_result, S, MATRIX_SIZE);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // Measure kernel execution time\n",
        "    printf(\"Executing CUDA kernel...\\\\n\");\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    conditionalRowReduction<<<gridSize, blockSize, sharedMemSize>>>(d_matrix, d_result, S, MATRIX_SIZE);\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "    // Calculate execution time\n",
        "    float kernelTime;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&kernelTime, start, stop));\n",
        "\n",
        "    // Check for kernel execution errors\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // Transfer results back to host\n",
        "    printf(\"Transferring results back to host...\\n\");\n",
        "    CUDA_CHECK(cudaMemcpy(h_result, d_result, resultBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Calculate total sum of result array\n",
        "    long long totalSum = calculateTotalSum(h_result, MATRIX_SIZE);\n",
        "\n",
        "    // Print required results\n",
        "    printf(\"\\\\n=== RESULTS ===\\\\n\");\n",
        "    printf(\"R[10]  = %d\\\\n\", h_result[10]);\n",
        "    printf(\"R[100] = %d\\\\n\", h_result[100]);\n",
        "    printf(\"R[200] = %d\\\\n\", h_result[200]);\n",
        "    printf(\"Total sum of R array = %lld\\n\", totalSum);\n",
        "    printf(\"\\n=== PERFORMANCE METRICS ===\\n\");\n",
        "    printf(\"Kernel execution time = %.4f ms\\n\", kernelTime);\n",
        "\n",
        "    // Calculate effective bandwidth\n",
        "    double totalBytes = matrixBytes + resultBytes;\n",
        "    double bandwidth = totalBytes / (kernelTime * 1e-3) / 1e9;\n",
        "    printf(\"Effective bandwidth = %.2f GB/s\\n\", bandwidth);\n",
        "\n",
        "    // Calculate throughput\n",
        "    long long totalOps = (long long)MATRIX_SIZE * MATRIX_SIZE;\n",
        "    double throughput = totalOps / (kernelTime * 1e-3) / 1e9;\n",
        "    printf(\"Throughput = %.2f GOPS\\n\", throughput);\n",
        "\n",
        "    // Optional: Show sample of results for verification\n",
        "    printf(\"\\n=== VERIFICATION SAMPLE ===\\n\");\n",
        "    printf(\"First 5 row sums: \");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%d \", h_result[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Cleanup memory\n",
        "    free(h_matrix);\n",
        "    free(h_result);\n",
        "    CUDA_CHECK(cudaFree(d_matrix));\n",
        "    CUDA_CHECK(cudaFree(d_result));\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "    printf(\"\\nProgram completed successfully!\\n\");\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KNPSCRlDxtLE"
      },
      "outputs": [],
      "source": [
        "!nvcc -o matrix_reduction matrix_reduction_simple.cu -arch=sm_60 -O3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIaCZBx8yQck",
        "outputId": "5b07630f-732b-4361-d63d-dc2f2d08096e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CUDA Conditional Row-wise Matrix Reduction ===\\nMatrix Size: 512x512\\nBlock Size: 256 threads\\nUsing personalized scalar S\n",
            "\n",
            "Initializing matrix...\n",
            "Transferring data to GPU...\n",
            "Executing CUDA kernel...\\nTransferring results back to host...\n",
            "\\n=== RESULTS ===\\nR[10]  = 844\\nR[100] = 612\\nR[200] = 1108\\nTotal sum of R array = 524552\n",
            "\n",
            "=== PERFORMANCE METRICS ===\n",
            "Kernel execution time = 0.0245 ms\n",
            "Effective bandwidth = 42.81 GB/s\n",
            "Throughput = 10.68 GOPS\n",
            "\n",
            "=== VERIFICATION SAMPLE ===\n",
            "First 5 row sums: 24264 600 360 532 672 \n",
            "\n",
            "Program completed successfully!\n"
          ]
        }
      ],
      "source": [
        "!./matrix_reduction"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}